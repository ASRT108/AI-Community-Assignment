{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCOk-MJbC_Da",
        "outputId": "f4c86fbe-754c-4c7b-a357-a717dccdbb99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "Epoch 1/20\n",
            "782/782 [==============================] - 56s 50ms/step - loss: 1.3681 - accuracy: 0.5070 - val_loss: 1.9680 - val_accuracy: 0.4342\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.9631 - accuracy: 0.6589 - val_loss: 1.5523 - val_accuracy: 0.5073\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.7952 - accuracy: 0.7218 - val_loss: 0.8801 - val_accuracy: 0.6944\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6759 - accuracy: 0.7640 - val_loss: 2.0250 - val_accuracy: 0.4907\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.5923 - accuracy: 0.7929 - val_loss: 0.9618 - val_accuracy: 0.6862\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.5246 - accuracy: 0.8170 - val_loss: 1.0517 - val_accuracy: 0.6724\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.4610 - accuracy: 0.8405 - val_loss: 1.0631 - val_accuracy: 0.6726\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.4020 - accuracy: 0.8592 - val_loss: 0.8086 - val_accuracy: 0.7410\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.3475 - accuracy: 0.8786 - val_loss: 0.8748 - val_accuracy: 0.7321\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.2980 - accuracy: 0.8951 - val_loss: 0.7740 - val_accuracy: 0.7665\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.2514 - accuracy: 0.9105 - val_loss: 0.7628 - val_accuracy: 0.7779\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.2127 - accuracy: 0.9243 - val_loss: 1.0105 - val_accuracy: 0.7426\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.1784 - accuracy: 0.9351 - val_loss: 1.0550 - val_accuracy: 0.7310\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.1535 - accuracy: 0.9462 - val_loss: 0.9493 - val_accuracy: 0.7770\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.1286 - accuracy: 0.9542 - val_loss: 1.2824 - val_accuracy: 0.7190\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.1226 - accuracy: 0.9565 - val_loss: 1.0154 - val_accuracy: 0.7654\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.1038 - accuracy: 0.9622 - val_loss: 0.8906 - val_accuracy: 0.7943\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.0909 - accuracy: 0.9675 - val_loss: 0.9980 - val_accuracy: 0.7861\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.0885 - accuracy: 0.9687 - val_loss: 1.2791 - val_accuracy: 0.7488\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.0820 - accuracy: 0.9712 - val_loss: 1.0871 - val_accuracy: 0.7832\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 1.0871 - accuracy: 0.7832\n",
            "Test accuracy: 0.7832000255584717\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar10  # Change here to load CIFAR-10 instead of CIFAR-100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset instead of CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # Change to 10 classes for CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)  # Change to 10 classes for CIFAR-10\n",
        "\n",
        "# Define ResNet-18 architecture\n",
        "def resnet_block(input_tensor, filters, strides=(1, 1), downsample=False):\n",
        "    identity = input_tensor\n",
        "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if downsample:\n",
        "        identity = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(identity)\n",
        "        identity = layers.BatchNormalization()(identity)\n",
        "    x = layers.add([x, identity])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def resnet18(input_shape=(32, 32, 3), num_classes=10):  # Change num_classes to 10 for CIFAR-10\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 128, downsample=True)\n",
        "    x = resnet_block(x, 128)\n",
        "    x = resnet_block(x, 256, downsample=True)\n",
        "    x = resnet_block(x, 256)\n",
        "    x = resnet_block(x, 512, downsample=True)\n",
        "    x = resnet_block(x, 512)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create ResNet-18 model\n",
        "model = resnet18()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset instead of CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # Change to 10 classes for CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)  # Change to 10 classes for CIFAR-10\n",
        "\n",
        "# Define SE block\n",
        "def se_block(input_tensor, ratio=16):\n",
        "    num_channels = input_tensor.shape[-1]\n",
        "    squeeze = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
        "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
        "    excitation = tf.expand_dims(tf.expand_dims(excitation, axis=1), axis=1)\n",
        "    return layers.multiply([input_tensor, excitation])\n",
        "\n",
        "# Define ResNet-18 with SE blocks\n",
        "def resnet18_se(input_shape=(32, 32, 3), num_classes=10):  # Change num_classes to 10 for CIFAR-10\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create ResNet-18 with SE blocks\n",
        "model = resnet18_se()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTXnonSuDSaO",
        "outputId": "3363a216-e054-4893-df84-4c55a7c0604e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 38s 34ms/step - loss: 1.0978 - accuracy: 0.6021 - val_loss: 1.3879 - val_accuracy: 0.5859\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.6582 - accuracy: 0.7683 - val_loss: 0.8070 - val_accuracy: 0.7246\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.5028 - accuracy: 0.8247 - val_loss: 0.7675 - val_accuracy: 0.7434\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.4001 - accuracy: 0.8614 - val_loss: 0.8164 - val_accuracy: 0.7302\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3138 - accuracy: 0.8900 - val_loss: 0.6812 - val_accuracy: 0.7875\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.2395 - accuracy: 0.9175 - val_loss: 0.7681 - val_accuracy: 0.7668\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.1839 - accuracy: 0.9341 - val_loss: 0.7429 - val_accuracy: 0.7819\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.1342 - accuracy: 0.9524 - val_loss: 1.0120 - val_accuracy: 0.7651\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.1024 - accuracy: 0.9635 - val_loss: 1.0737 - val_accuracy: 0.7465\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.0831 - accuracy: 0.9708 - val_loss: 0.6891 - val_accuracy: 0.8288\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.0714 - accuracy: 0.9750 - val_loss: 0.9693 - val_accuracy: 0.7863\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.0623 - accuracy: 0.9779 - val_loss: 0.9860 - val_accuracy: 0.7891\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0574 - accuracy: 0.9803 - val_loss: 0.7515 - val_accuracy: 0.8213\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0530 - accuracy: 0.9808 - val_loss: 1.1999 - val_accuracy: 0.7653\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0433 - accuracy: 0.9848 - val_loss: 0.7394 - val_accuracy: 0.8330\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0436 - accuracy: 0.9847 - val_loss: 0.8147 - val_accuracy: 0.8287\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0401 - accuracy: 0.9862 - val_loss: 0.8734 - val_accuracy: 0.8186\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0393 - accuracy: 0.9866 - val_loss: 0.8205 - val_accuracy: 0.8335\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.0315 - accuracy: 0.9888 - val_loss: 0.9551 - val_accuracy: 0.8225\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.0383 - accuracy: 0.9867 - val_loss: 0.9705 - val_accuracy: 0.8188\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.9705 - accuracy: 0.8188\n",
            "Test accuracy: 0.8187999725341797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset instead of CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # Change to 10 classes for CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)  # Change to 10 classes for CIFAR-10\n",
        "\n",
        "# Define CNN model without attention mechanism\n",
        "def simple_cnn():\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)  # Change to 10 classes for CIFAR-10\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = simple_cnn()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5opSgd2lECKv",
        "outputId": "669900d3-716a-4f21-f935-5c2ffec2f771"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 9s 9ms/step - loss: 1.3826 - accuracy: 0.4983 - val_loss: 1.0374 - val_accuracy: 0.6259\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9268 - accuracy: 0.6727 - val_loss: 0.8397 - val_accuracy: 0.7049\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7278 - accuracy: 0.7453 - val_loss: 0.7884 - val_accuracy: 0.7278\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.5811 - accuracy: 0.7974 - val_loss: 0.8007 - val_accuracy: 0.7272\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4530 - accuracy: 0.8430 - val_loss: 0.7345 - val_accuracy: 0.7571\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3345 - accuracy: 0.8832 - val_loss: 0.7773 - val_accuracy: 0.7622\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2377 - accuracy: 0.9177 - val_loss: 0.8836 - val_accuracy: 0.7465\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.1701 - accuracy: 0.9410 - val_loss: 0.9654 - val_accuracy: 0.7547\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.1313 - accuracy: 0.9546 - val_loss: 1.0749 - val_accuracy: 0.7501\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.1077 - accuracy: 0.9628 - val_loss: 1.1507 - val_accuracy: 0.7482\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1507 - accuracy: 0.7482\n",
            "Test accuracy: 0.748199999332428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset instead of CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # Change to 10 classes for CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)  # Change to 10 classes for CIFAR-10\n",
        "\n",
        "# Define SE block\n",
        "def se_block(input_tensor, ratio=16):\n",
        "    num_channels = input_tensor.shape[-1]\n",
        "    squeeze = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
        "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
        "    excitation = tf.expand_dims(tf.expand_dims(excitation, axis=1), axis=1)\n",
        "    return layers.multiply([input_tensor, excitation])\n",
        "\n",
        "# Define CNN model with SE block\n",
        "def simple_cnn_se():\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)  # Change to 10 classes for CIFAR-10\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = simple_cnn_se()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_SRjbBMDi1U",
        "outputId": "d74a8d5e-70ec-4408-be0f-88cf30fea219"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 12s 12ms/step - loss: 1.5174 - accuracy: 0.4465 - val_loss: 1.1971 - val_accuracy: 0.5671\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0538 - accuracy: 0.6265 - val_loss: 0.9522 - val_accuracy: 0.6601\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.8527 - accuracy: 0.7029 - val_loss: 0.8489 - val_accuracy: 0.7074\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.7116 - accuracy: 0.7533 - val_loss: 0.7549 - val_accuracy: 0.7396\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5952 - accuracy: 0.7930 - val_loss: 0.7326 - val_accuracy: 0.7489\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.4904 - accuracy: 0.8287 - val_loss: 0.7850 - val_accuracy: 0.7476\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3883 - accuracy: 0.8644 - val_loss: 0.7717 - val_accuracy: 0.7505\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.2897 - accuracy: 0.8992 - val_loss: 0.8777 - val_accuracy: 0.7527\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.2065 - accuracy: 0.9274 - val_loss: 1.0008 - val_accuracy: 0.7513\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.1572 - accuracy: 0.9456 - val_loss: 1.1745 - val_accuracy: 0.7434\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.1745 - accuracy: 0.7434\n",
            "Test accuracy: 0.743399977684021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset instead of CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)  # Change to 10 classes for CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)  # Change to 10 classes for CIFAR-10\n",
        "\n",
        "# Define MobileNet architecture\n",
        "def mobile_net(input_shape=(32, 32, 3), num_classes=10):  # Change num_classes to 10 for CIFAR-10\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 64, (3, 3))\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3), strides=(2, 2))\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3))\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3), strides=(2, 2))\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3))\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 512, (3, 3), strides=(2, 2))\n",
        "    for _ in range(5):\n",
        "        x = depthwise_separable_conv_block(x, 512, (3, 3))\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 1024, (3, 3), strides=(2, 2))\n",
        "    x = depthwise_separable_conv_block(x, 1024, (3, 3))\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def depthwise_separable_conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Create MobileNet model\n",
        "model = mobile_net()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN54C8q1ELPE",
        "outputId": "9d45c567-1637-467d-bdec-cec967f54343"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 35s 25ms/step - loss: 1.9091 - accuracy: 0.3012 - val_loss: 1.6926 - val_accuracy: 0.3726\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.5426 - accuracy: 0.4404 - val_loss: 1.8552 - val_accuracy: 0.4173\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.3779 - accuracy: 0.5084 - val_loss: 1.5113 - val_accuracy: 0.4630\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.2471 - accuracy: 0.5571 - val_loss: 2.5551 - val_accuracy: 0.4512\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.1669 - accuracy: 0.5901 - val_loss: 1.2667 - val_accuracy: 0.5771\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.0427 - accuracy: 0.6361 - val_loss: 1.2493 - val_accuracy: 0.5755\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 0.9818 - accuracy: 0.6587 - val_loss: 1.2216 - val_accuracy: 0.6119\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.9012 - accuracy: 0.6872 - val_loss: 1.3297 - val_accuracy: 0.5865\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 0.8308 - accuracy: 0.7138 - val_loss: 1.0222 - val_accuracy: 0.6477\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.7436 - accuracy: 0.7399 - val_loss: 0.9985 - val_accuracy: 0.6660\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 0.7259 - accuracy: 0.7503 - val_loss: 1.2305 - val_accuracy: 0.6390\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.6990 - accuracy: 0.7591 - val_loss: 0.9599 - val_accuracy: 0.6732\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 0.5858 - accuracy: 0.7970 - val_loss: 0.9815 - val_accuracy: 0.6878\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.5421 - accuracy: 0.8108 - val_loss: 2.0211 - val_accuracy: 0.5142\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.5729 - accuracy: 0.8024 - val_loss: 0.9363 - val_accuracy: 0.7031\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.4756 - accuracy: 0.8375 - val_loss: 0.9374 - val_accuracy: 0.7036\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.4198 - accuracy: 0.8561 - val_loss: 0.9252 - val_accuracy: 0.7167\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.3892 - accuracy: 0.8674 - val_loss: 1.2571 - val_accuracy: 0.6332\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.3702 - accuracy: 0.8719 - val_loss: 1.3230 - val_accuracy: 0.6374\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 0.3196 - accuracy: 0.8883 - val_loss: 1.0193 - val_accuracy: 0.7146\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 1.0193 - accuracy: 0.7146\n",
            "Test accuracy: 0.7146000266075134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 data instead of CIFAR-100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices (for use with categorical_crossentropy)\n",
        "y_train = to_categorical(y_train, 10)  # Change to 10 classes for CIFAR-10\n",
        "y_test = to_categorical(y_test, 10)  # Change to 10 classes for CIFAR-10\n",
        "\n",
        "def squeeze_excite_block(input_tensor, ratio=16):\n",
        "    init = input_tensor\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = layers.GlobalAveragePooling2D()(init)\n",
        "    se = layers.Reshape(se_shape)(se)\n",
        "    se = layers.Dense(filters // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
        "\n",
        "    x = layers.multiply([init, se])\n",
        "    return x\n",
        "\n",
        "def depthwise_separable_conv_block(input_tensor, filters, kernel_size, strides=(1, 1), include_se=False):\n",
        "    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    if include_se:\n",
        "        x = squeeze_excite_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def MobileNetSE(input_shape=(32, 32, 3), num_classes=10):  # Change num_classes to 10 for CIFAR-10\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Adapted MobileNet architecture with SE blocks\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 64, (3, 3), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3), strides=(2, 2), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3), strides=(2, 2), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 512, (3, 3), strides=(2, 2), include_se=True)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Instantiate and compile the model\n",
        "model = MobileNetSE()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amw5DxSWEq1z",
        "outputId": "c80b5d9c-581c-4339-d7cd-91ced7c54d44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 29s 23ms/step - loss: 1.4525 - accuracy: 0.4709 - val_loss: 1.4384 - val_accuracy: 0.4979\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 1.0800 - accuracy: 0.6143 - val_loss: 1.2301 - val_accuracy: 0.5672\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.8862 - accuracy: 0.6867 - val_loss: 1.0008 - val_accuracy: 0.6502\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.7638 - accuracy: 0.7293 - val_loss: 1.1341 - val_accuracy: 0.6207\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6648 - accuracy: 0.7654 - val_loss: 0.9690 - val_accuracy: 0.6793\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.5846 - accuracy: 0.7951 - val_loss: 0.9469 - val_accuracy: 0.6886\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5229 - accuracy: 0.8138 - val_loss: 0.9228 - val_accuracy: 0.6985\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4606 - accuracy: 0.8337 - val_loss: 0.9181 - val_accuracy: 0.7090\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4105 - accuracy: 0.8532 - val_loss: 1.0098 - val_accuracy: 0.7003\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.3625 - accuracy: 0.8708 - val_loss: 0.9824 - val_accuracy: 0.7158\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.3251 - accuracy: 0.8835 - val_loss: 1.1879 - val_accuracy: 0.6858\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.2928 - accuracy: 0.8950 - val_loss: 1.0551 - val_accuracy: 0.7083\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.2588 - accuracy: 0.9074 - val_loss: 1.0214 - val_accuracy: 0.7220\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.2365 - accuracy: 0.9149 - val_loss: 1.0962 - val_accuracy: 0.7229\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.2162 - accuracy: 0.9228 - val_loss: 1.1549 - val_accuracy: 0.7258\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.1964 - accuracy: 0.9288 - val_loss: 1.1327 - val_accuracy: 0.7222\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.1830 - accuracy: 0.9336 - val_loss: 1.4094 - val_accuracy: 0.6884\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.1749 - accuracy: 0.9361 - val_loss: 1.1946 - val_accuracy: 0.7241\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.1584 - accuracy: 0.9441 - val_loss: 1.2693 - val_accuracy: 0.7132\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.1473 - accuracy: 0.9475 - val_loss: 1.1971 - val_accuracy: 0.7296\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 1.1971 - accuracy: 0.7296\n",
            "Test accuracy: 0.7296000123023987\n"
          ]
        }
      ]
    }
  ]
}