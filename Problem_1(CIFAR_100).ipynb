{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Resnet18\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "# Define ResNet-18 architecture\n",
        "def resnet_block(input_tensor, filters, strides=(1, 1), downsample=False):\n",
        "    identity = input_tensor\n",
        "    x = layers.Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if downsample:\n",
        "        identity = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding='same')(identity)\n",
        "        identity = layers.BatchNormalization()(identity)\n",
        "    x = layers.add([x, identity])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def resnet18(input_shape=(32, 32, 3), num_classes=100):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 64)\n",
        "    x = resnet_block(x, 128, downsample=True)\n",
        "    x = resnet_block(x, 128)\n",
        "    x = resnet_block(x, 256, downsample=True)\n",
        "    x = resnet_block(x, 256)\n",
        "    x = resnet_block(x, 512, downsample=True)\n",
        "    x = resnet_block(x, 512)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create ResNet-18 model\n",
        "model = resnet18()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32xtBQEXunsD",
        "outputId": "fdce91a6-cfbe-4293-db80-aa48247128dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 54s 53ms/step - loss: 3.6137 - accuracy: 0.1497 - val_loss: 4.2021 - val_accuracy: 0.1222\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.8554 - accuracy: 0.2751 - val_loss: 3.5164 - val_accuracy: 0.2158\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.4491 - accuracy: 0.3561 - val_loss: 2.9016 - val_accuracy: 0.2932\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.1587 - accuracy: 0.4196 - val_loss: 2.4881 - val_accuracy: 0.3663\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 1.9264 - accuracy: 0.4728 - val_loss: 2.3023 - val_accuracy: 0.4047\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 1.7319 - accuracy: 0.5207 - val_loss: 2.7916 - val_accuracy: 0.3390\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 1.5540 - accuracy: 0.5614 - val_loss: 2.4463 - val_accuracy: 0.4008\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 1.3970 - accuracy: 0.5989 - val_loss: 2.6288 - val_accuracy: 0.3847\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 1.2285 - accuracy: 0.6429 - val_loss: 2.2050 - val_accuracy: 0.4649\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 1.0729 - accuracy: 0.6838 - val_loss: 2.7082 - val_accuracy: 0.4047\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.9165 - accuracy: 0.7243 - val_loss: 2.1549 - val_accuracy: 0.4782\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.7541 - accuracy: 0.7677 - val_loss: 2.3487 - val_accuracy: 0.4747\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6066 - accuracy: 0.8111 - val_loss: 2.5695 - val_accuracy: 0.4674\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.4871 - accuracy: 0.8449 - val_loss: 2.7465 - val_accuracy: 0.4573\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.3909 - accuracy: 0.8741 - val_loss: 2.8252 - val_accuracy: 0.4475\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.3143 - accuracy: 0.8977 - val_loss: 2.7309 - val_accuracy: 0.4865\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.2613 - accuracy: 0.9146 - val_loss: 2.9536 - val_accuracy: 0.4715\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.2471 - accuracy: 0.9188 - val_loss: 2.9754 - val_accuracy: 0.4829\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.1943 - accuracy: 0.9375 - val_loss: 3.1231 - val_accuracy: 0.4885\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 0.1863 - accuracy: 0.9391 - val_loss: 3.1300 - val_accuracy: 0.4905\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 3.1300 - accuracy: 0.4905\n",
            "Test accuracy: 0.49050000309944153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAS7dyzbtKiK",
        "outputId": "01a1ece3-8bf2-4908-e6b7-86b538aafb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 39s 35ms/step - loss: 3.3821 - accuracy: 0.1746 - val_loss: 3.1741 - val_accuracy: 0.2200\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 2.3898 - accuracy: 0.3611 - val_loss: 3.4089 - val_accuracy: 0.2560\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.9084 - accuracy: 0.4728 - val_loss: 2.4713 - val_accuracy: 0.3745\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.5814 - accuracy: 0.5506 - val_loss: 2.2160 - val_accuracy: 0.4283\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 1.3214 - accuracy: 0.6178 - val_loss: 2.4902 - val_accuracy: 0.3952\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 1.0835 - accuracy: 0.6797 - val_loss: 2.1956 - val_accuracy: 0.4640\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.8646 - accuracy: 0.7372 - val_loss: 1.9459 - val_accuracy: 0.5171\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.6586 - accuracy: 0.7951 - val_loss: 2.5025 - val_accuracy: 0.4744\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.4801 - accuracy: 0.8501 - val_loss: 2.0338 - val_accuracy: 0.5396\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.3472 - accuracy: 0.8887 - val_loss: 2.1809 - val_accuracy: 0.5393\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.2467 - accuracy: 0.9230 - val_loss: 2.3847 - val_accuracy: 0.5267\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 0.1974 - accuracy: 0.9366 - val_loss: 2.5952 - val_accuracy: 0.5154\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.1603 - accuracy: 0.9478 - val_loss: 3.2024 - val_accuracy: 0.4913\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.1476 - accuracy: 0.9521 - val_loss: 2.5831 - val_accuracy: 0.5489\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.1312 - accuracy: 0.9582 - val_loss: 2.7164 - val_accuracy: 0.5375\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.1178 - accuracy: 0.9616 - val_loss: 2.8310 - val_accuracy: 0.5412\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.1145 - accuracy: 0.9631 - val_loss: 2.7021 - val_accuracy: 0.5432\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.1012 - accuracy: 0.9671 - val_loss: 3.0175 - val_accuracy: 0.5195\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0976 - accuracy: 0.9678 - val_loss: 2.9471 - val_accuracy: 0.5470\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 0.0895 - accuracy: 0.9710 - val_loss: 3.1455 - val_accuracy: 0.5288\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 3.1455 - accuracy: 0.5288\n",
            "Test accuracy: 0.5288000106811523\n"
          ]
        }
      ],
      "source": [
        "#Resnet 18 with Squeeze and excitation attention\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "# Define SE block\n",
        "def se_block(input_tensor, ratio=16):\n",
        "    num_channels = input_tensor.shape[-1]\n",
        "    squeeze = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
        "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
        "    excitation = tf.expand_dims(tf.expand_dims(excitation, axis=1), axis=1)\n",
        "    return layers.multiply([input_tensor, excitation])\n",
        "\n",
        "# Define ResNet-18 with SE blocks\n",
        "def resnet18_se(input_shape=(32, 32, 3), num_classes=100):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = se_block(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create ResNet-18 with SE blocks\n",
        "model = resnet18_se()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "# Create CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "epochs = 10\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Display training accuracy and loss for each epoch\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch\", epoch+1, \"Training Accuracy:\", history.history['accuracy'][epoch], \"Training Loss:\", history.history['loss'][epoch])\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGQIkNUhutBt",
        "outputId": "fa29fdde-7d47-429c-8156-e0e5c8588357"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 10s 8ms/step - loss: 4.3839 - accuracy: 0.0303 - val_loss: 4.0911 - val_accuracy: 0.0743\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 3.9905 - accuracy: 0.0803 - val_loss: 3.7248 - val_accuracy: 0.1222\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 3.7797 - accuracy: 0.1101 - val_loss: 3.5066 - val_accuracy: 0.1656\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.6422 - accuracy: 0.1292 - val_loss: 3.3911 - val_accuracy: 0.1874\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.5423 - accuracy: 0.1500 - val_loss: 3.3436 - val_accuracy: 0.2033\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 3.4530 - accuracy: 0.1639 - val_loss: 3.2043 - val_accuracy: 0.2199\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.3884 - accuracy: 0.1736 - val_loss: 3.1570 - val_accuracy: 0.2343\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.3366 - accuracy: 0.1882 - val_loss: 3.0867 - val_accuracy: 0.2392\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.2754 - accuracy: 0.1949 - val_loss: 3.0540 - val_accuracy: 0.2486\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 3.2267 - accuracy: 0.2020 - val_loss: 3.0166 - val_accuracy: 0.2625\n",
            "Epoch 1 Training Accuracy: 0.03034999966621399 Training Loss: 4.3839192390441895\n",
            "Epoch 2 Training Accuracy: 0.08030000329017639 Training Loss: 3.9905245304107666\n",
            "Epoch 3 Training Accuracy: 0.11007499694824219 Training Loss: 3.779686212539673\n",
            "Epoch 4 Training Accuracy: 0.12917500734329224 Training Loss: 3.6421799659729004\n",
            "Epoch 5 Training Accuracy: 0.15000000596046448 Training Loss: 3.5422563552856445\n",
            "Epoch 6 Training Accuracy: 0.16387499868869781 Training Loss: 3.453010082244873\n",
            "Epoch 7 Training Accuracy: 0.17364999651908875 Training Loss: 3.388380765914917\n",
            "Epoch 8 Training Accuracy: 0.18822500109672546 Training Loss: 3.33656907081604\n",
            "Epoch 9 Training Accuracy: 0.194924995303154 Training Loss: 3.275416851043701\n",
            "Epoch 10 Training Accuracy: 0.20200000703334808 Training Loss: 3.226689338684082\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.9981 - accuracy: 0.2722\n",
            "Test accuracy: 0.27219998836517334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple CNN with squeeze and excitation attention\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "# Define SE block\n",
        "def se_block(input_tensor, ratio=16):\n",
        "    num_channels = input_tensor.shape[-1]\n",
        "    squeeze = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    excitation = layers.Dense(num_channels // ratio, activation='relu')(squeeze)\n",
        "    excitation = layers.Dense(num_channels, activation='sigmoid')(excitation)\n",
        "    excitation = tf.expand_dims(tf.expand_dims(excitation, axis=1), axis=1)\n",
        "    return layers.multiply([input_tensor, excitation])\n",
        "\n",
        "# Define CNN model with SE block\n",
        "def simple_cnn_se():\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = se_block(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    outputs = layers.Dense(100, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "model = simple_cnn_se()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9FKp6Nwy6qg",
        "outputId": "98cada0b-754d-421f-b4e9-4e0d52543f5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 14s 11ms/step - loss: 3.8091 - accuracy: 0.1179 - val_loss: 3.2456 - val_accuracy: 0.2160\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.9765 - accuracy: 0.2639 - val_loss: 2.7926 - val_accuracy: 0.3036\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 2.5515 - accuracy: 0.3476 - val_loss: 2.5654 - val_accuracy: 0.3547\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 2.2290 - accuracy: 0.4196 - val_loss: 2.4209 - val_accuracy: 0.3867\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.9587 - accuracy: 0.4778 - val_loss: 2.3149 - val_accuracy: 0.4120\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.7111 - accuracy: 0.5360 - val_loss: 2.4431 - val_accuracy: 0.3967\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 1.4741 - accuracy: 0.5903 - val_loss: 2.4077 - val_accuracy: 0.4168\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 1.2338 - accuracy: 0.6490 - val_loss: 2.5099 - val_accuracy: 0.4236\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 1.0046 - accuracy: 0.7060 - val_loss: 2.7398 - val_accuracy: 0.4154\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.7990 - accuracy: 0.7625 - val_loss: 3.0702 - val_accuracy: 0.4065\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 3.0702 - accuracy: 0.4065\n",
            "Test accuracy: 0.4065000116825104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mobilenet\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "# Define MobileNet architecture\n",
        "def mobile_net(input_shape=(32, 32, 3), num_classes=100):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 64, (3, 3))\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3), strides=(2, 2))\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3))\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3), strides=(2, 2))\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3))\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 512, (3, 3), strides=(2, 2))\n",
        "    for _ in range(5):\n",
        "        x = depthwise_separable_conv_block(x, 512, (3, 3))\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 1024, (3, 3), strides=(2, 2))\n",
        "    x = depthwise_separable_conv_block(x, 1024, (3, 3))\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def depthwise_separable_conv_block(input_tensor, filters, kernel_size, strides=(1, 1)):\n",
        "    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Create MobileNet model\n",
        "model = mobile_net()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xczoQ0Ix6u63",
        "outputId": "62dc7d3d-b71b-416c-9908-5e401c9a5f19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 37s 26ms/step - loss: 4.2698 - accuracy: 0.0586 - val_loss: 3.9954 - val_accuracy: 0.0836\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 3.7628 - accuracy: 0.1251 - val_loss: 4.1732 - val_accuracy: 0.1157\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 3.5268 - accuracy: 0.1572 - val_loss: 5.2598 - val_accuracy: 0.1259\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 3.2976 - accuracy: 0.1941 - val_loss: 3.6979 - val_accuracy: 0.1686\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 3.1198 - accuracy: 0.2217 - val_loss: 4.0689 - val_accuracy: 0.1579\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.9576 - accuracy: 0.2535 - val_loss: 3.1841 - val_accuracy: 0.2275\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.8087 - accuracy: 0.2784 - val_loss: 3.1313 - val_accuracy: 0.2395\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 2.6600 - accuracy: 0.3073 - val_loss: 2.9438 - val_accuracy: 0.2714\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.5422 - accuracy: 0.3337 - val_loss: 3.2527 - val_accuracy: 0.2703\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.4172 - accuracy: 0.3594 - val_loss: 3.0030 - val_accuracy: 0.2899\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.3355 - accuracy: 0.3743 - val_loss: 2.8379 - val_accuracy: 0.3083\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 18s 24ms/step - loss: 2.2038 - accuracy: 0.4061 - val_loss: 2.7970 - val_accuracy: 0.3098\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 2.0903 - accuracy: 0.4304 - val_loss: 2.7841 - val_accuracy: 0.3213\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.9998 - accuracy: 0.4486 - val_loss: 2.6288 - val_accuracy: 0.3489\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.8856 - accuracy: 0.4730 - val_loss: 2.7655 - val_accuracy: 0.3426\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.7860 - accuracy: 0.4979 - val_loss: 3.0365 - val_accuracy: 0.3078\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.7061 - accuracy: 0.5164 - val_loss: 2.8096 - val_accuracy: 0.3466\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.6090 - accuracy: 0.5386 - val_loss: 2.8605 - val_accuracy: 0.3345\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.5424 - accuracy: 0.5555 - val_loss: 2.8068 - val_accuracy: 0.3593\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 19s 24ms/step - loss: 1.4392 - accuracy: 0.5807 - val_loss: 2.8958 - val_accuracy: 0.3519\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 2.8958 - accuracy: 0.3519\n",
            "Test accuracy: 0.35190001130104065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mobilenet with Squeeze and excitation attention\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Load CIFAR-100 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Normalize pixel values\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert class vectors to binary class matrices (for use with categorical_crossentropy)\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test = to_categorical(y_test, 100)\n",
        "\n",
        "def squeeze_excite_block(input_tensor, ratio=16):\n",
        "    init = input_tensor\n",
        "    channel_axis = -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = layers.GlobalAveragePooling2D()(init)\n",
        "    se = layers.Reshape(se_shape)(se)\n",
        "    se = layers.Dense(filters // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
        "\n",
        "    x = layers.multiply([init, se])\n",
        "    return x\n",
        "def depthwise_separable_conv_block(input_tensor, filters, kernel_size, strides=(1, 1), include_se=False):\n",
        "    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    if include_se:\n",
        "        x = squeeze_excite_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def MobileNetSE(input_shape=(32, 32, 3), num_classes=100):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Adapted MobileNet architecture with SE blocks\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = depthwise_separable_conv_block(x, 64, (3, 3), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3), strides=(2, 2), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 128, (3, 3), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3), strides=(2, 2), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 256, (3, 3), include_se=True)\n",
        "    x = depthwise_separable_conv_block(x, 512, (3, 3), strides=(2, 2), include_se=True)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Instantiate and compile the model\n",
        "model = MobileNetSE()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=20, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsPnhvds6zJc",
        "outputId": "7a5c2d40-371f-4e97-d454-bba9233a22e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - 29s 23ms/step - loss: 3.5903 - accuracy: 0.1570 - val_loss: 3.2334 - val_accuracy: 0.2125\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.8632 - accuracy: 0.2802 - val_loss: 2.9675 - val_accuracy: 0.2768\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 2.5077 - accuracy: 0.3511 - val_loss: 2.7064 - val_accuracy: 0.3156\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.2471 - accuracy: 0.4074 - val_loss: 2.6051 - val_accuracy: 0.3504\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 2.0382 - accuracy: 0.4493 - val_loss: 2.4109 - val_accuracy: 0.3845\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.8633 - accuracy: 0.4925 - val_loss: 2.5199 - val_accuracy: 0.3753\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.7092 - accuracy: 0.5282 - val_loss: 2.3728 - val_accuracy: 0.4065\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.5696 - accuracy: 0.5621 - val_loss: 2.3726 - val_accuracy: 0.4168\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 18s 23ms/step - loss: 1.4421 - accuracy: 0.5926 - val_loss: 2.4538 - val_accuracy: 0.4020\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.3202 - accuracy: 0.6219 - val_loss: 2.6153 - val_accuracy: 0.3962\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.2100 - accuracy: 0.6489 - val_loss: 2.5396 - val_accuracy: 0.4112\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 1.1057 - accuracy: 0.6780 - val_loss: 2.5906 - val_accuracy: 0.4028\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 1.0141 - accuracy: 0.7002 - val_loss: 2.7443 - val_accuracy: 0.3931\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 18s 22ms/step - loss: 0.9295 - accuracy: 0.7232 - val_loss: 2.6399 - val_accuracy: 0.4226\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.8530 - accuracy: 0.7427 - val_loss: 2.8166 - val_accuracy: 0.4086\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 20s 26ms/step - loss: 0.7758 - accuracy: 0.7609 - val_loss: 2.8298 - val_accuracy: 0.4086\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 19s 25ms/step - loss: 0.7147 - accuracy: 0.7785 - val_loss: 2.8888 - val_accuracy: 0.4126\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.6508 - accuracy: 0.7986 - val_loss: 3.0590 - val_accuracy: 0.3994\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6030 - accuracy: 0.8094 - val_loss: 3.1134 - val_accuracy: 0.4063\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 17s 22ms/step - loss: 0.5554 - accuracy: 0.8243 - val_loss: 3.2286 - val_accuracy: 0.4112\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 3.2286 - accuracy: 0.4112\n",
            "Test accuracy: 0.41119998693466187\n"
          ]
        }
      ]
    }
  ]
}